{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e961fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
      "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
      "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
      "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
      "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
      "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
      "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
      "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
      "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
      "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
      "\n",
      "[418 rows x 11 columns]\n",
      "(7, 418)\n"
     ]
    }
   ],
   "source": [
    "#This code is a basic implementation of a 1 hidden layer neural network model for binary classification applied for the titanic kaggle competition\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "#Extract Passenger information to Xtrain with Pclass, Sex, Age, SibSp, Parch, Fare, Embarked and Ytrain with surpervivence info \n",
    "\n",
    "train_df = pd.read_csv (r'../data/train.csv')\n",
    "Xtrain = train_df.drop([\"Ticket\",\"Name\",\"Cabin\",\"PassengerId\", \"Survived\"], axis = 1)\n",
    "Ytrain = train_df[\"Survived\"].to_numpy()\n",
    "Ytrain = Ytrain.reshape((Ytrain.shape[0],1))\n",
    "Xtrain[\"Sex\"] = Xtrain[\"Sex\"].apply(lambda x: 0 if x == \"male\" else 1)\n",
    "Xtrain[\"Age\"] = Xtrain[\"Age\"].fillna(Xtrain[\"Age\"].mean())\n",
    "Xtrain[\"Embarked\"] = Xtrain[\"Embarked\"].apply(lambda x: 0 if x == \"C\" else 1 if x == \"Q\" else 2 )\n",
    "Xtrain = Xtrain.to_numpy().T\n",
    "\n",
    "#Extract test information for making the submision file\n",
    "test_df = pd.read_csv(r'../data/test.csv')\n",
    "print(test_df)\n",
    "Xtest = test_df.drop([\"Ticket\",\"Name\",\"Cabin\",\"PassengerId\"], axis = 1)\n",
    "Xtest[\"Sex\"] = Xtest[\"Sex\"].apply(lambda x: 0 if x == \"male\" else 1)\n",
    "Xtest[\"Age\"] = Xtest[\"Age\"].fillna(Xtest[\"Age\"].mean())\n",
    "Xtest[\"Embarked\"] = Xtest[\"Embarked\"].apply(lambda x: 0 if x == \"C\" else 1 if x == \"Q\" else 2 )\n",
    "Xtest = Xtest.to_numpy().T\n",
    "print(Xtest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7037f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "[[3.99666667]\n",
      " [3.99333333]\n",
      " [3.99      ]]\n"
     ]
    }
   ],
   "source": [
    "class tanh:\n",
    "    \"\"\"\n",
    "    self.val and self.dev are the value and derivate of the tanh function for a given z\n",
    "    \"\"\"\n",
    "    def __init__(self, z):\n",
    "        \"\"\"\n",
    "        z: numpy array or scalar\n",
    "        \"\"\"\n",
    "        self.val = np.tanh(z)\n",
    "        g = self.val\n",
    "        self.dev = 1-g**2\n",
    "\n",
    "class relu:\n",
    "    \"\"\"\n",
    "    self.val and self.dev are the value and derivate of the ReLU function for a given z\n",
    "    \"\"\"\n",
    "    def __init__(self, z):\n",
    "        \"\"\"\n",
    "        z: numpy array or scalar\n",
    "        \"\"\"\n",
    "        self.val = np.maximum(0,z)\n",
    "        g = self.val\n",
    "        try:\n",
    "            if z < 0:\n",
    "                self.dev = 0\n",
    "            else:\n",
    "                self.dev = 1\n",
    "        except:\n",
    "            vf = np.vectorize(lambda x: 0 if x < 0 else 1)\n",
    "            self.dev = vf(z)\n",
    "       \n",
    "\n",
    "class sigmoid:\n",
    "    \"\"\"\n",
    "    self.val and self.dev are the value and derivate of the sigmoid function for a given z\n",
    "    \"\"\"\n",
    "    def __init__(self, z):\n",
    "        \"\"\"\n",
    "        z: numpy array or scalar\n",
    "        \"\"\"\n",
    "        self.val = 1/(1+np.exp(-z))\n",
    "        g = self.val\n",
    "        self.dev = g*(1-g)\n",
    "\n",
    "\n",
    "def prediction(X, w1, b1, w2, b2, act1, act2):\n",
    "    \"\"\"\n",
    "    X: Matrix of size (input characteristics, number of examples)\n",
    "    w1: Matrix of size (first layer neurons, input characteristics)\n",
    "    b1: bias scalar for firsr layer\n",
    "    w1: Vector of size (first layer neurons,1)\n",
    "    b1: bias scalar for output layer\n",
    "    act1: activation function for first layer\n",
    "    act2: activation function for output layer\n",
    "    \n",
    "    \n",
    "    \"\"\" \n",
    "    Z1 = np.dot(w1,X)+b1\n",
    "    A1 = act1(Z1).val\n",
    "    Z2 = np.dot(w2.T,A1)+b2\n",
    "    A2 = act2(Z2).val\n",
    "    f = np.vectorize(lambda x: 0 if x < 0.5 else 1)\n",
    "    return f(A2).T        \n",
    "    \n",
    "\n",
    "def propagate(X,Y,w1, b1, w2, b2, act1, act2,learning_rate):\n",
    "    m = X.shape[1]\n",
    "    Z1 = np.dot(w1,X)+b1\n",
    "    A1 = act1(Z1).val\n",
    "    Z2 = np.dot(w2.T,A1)+b2\n",
    "    A2 = act2(Z2).val\n",
    "    print(A2.shape)\n",
    "    \n",
    "    dZ2 = A2-Y.T\n",
    "    dW2 = np.dot(dZ2,A1.T)/m\n",
    "    db2 = np.sum(dZ2,axis = 1,keepdims = True)/m\n",
    "    dZ1 = np.dot(w2,dZ2)*act1(Z1).dev\n",
    "    dW1 = np.dot(dZ1,X.T)/m\n",
    "    db1 = np.sum(dZ1,axis = 1,keepdims = True)/m\n",
    "    \n",
    "    w1 = w1-learning_rate*dW1\n",
    "    w2 = w2-learning_rate*dW2\n",
    "    b1 = b1-learning_rate*db1\n",
    "    b2 = b2-learning_rate*db2\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "w1 = np.array([[1,0],[4,0],[7,1]])\n",
    "b1 = 4\n",
    "w2 = np.array([1,2,3]).reshape((3,1))\n",
    "b2 = 5\n",
    "Y = np.array([1,0,1]).reshape((3,1))\n",
    "a = propagate(X,Y,w1, b1, w2, b2, relu, sigmoid,0.01)\n",
    "print(a[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
